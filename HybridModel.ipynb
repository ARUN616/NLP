{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba1934b-1d3a-49cf-9c8e-b9c99e4b77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b536aff-110c-416a-ac33-1029675945f0",
   "metadata": {},
   "source": [
    "## Data Import and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8dee81b0-c61a-4c72-a701-69a88d3e6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3571684-c67e-43db-877e-6fe4e5c693e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-02-2015 11:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-02-2015 11:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-02-2015 11:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-02-2015 11:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.703010e+17</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cjmcginnis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24-02-2015 11:13</td>\n",
       "      <td>San Francisco CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  5.703010e+17          positive                        0.3486   \n",
       "1  5.703010e+17          negative                        1.0000   \n",
       "2  5.703010e+17          negative                        1.0000   \n",
       "3  5.703010e+17          negative                        1.0000   \n",
       "4  5.703010e+17          positive                        0.6745   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                     0.0000  Virgin America   \n",
       "1     Bad Flight                     0.7033  Virgin America   \n",
       "2     Can't Tell                     1.0000  Virgin America   \n",
       "3     Can't Tell                     0.6842  Virgin America   \n",
       "4            NaN                     0.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN    jnardino                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN    jnardino                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN  cjmcginnis                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "1  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "2  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "3  @VirginAmerica seriously would pay $30 a fligh...         NaN   \n",
       "4  @VirginAmerica yes, nearly every time I fly VX...         NaN   \n",
       "\n",
       "      tweet_created    tweet_location               user_timezone  \n",
       "0  24-02-2015 11:15               NaN  Pacific Time (US & Canada)  \n",
       "1  24-02-2015 11:15               NaN  Pacific Time (US & Canada)  \n",
       "2  24-02-2015 11:14               NaN  Pacific Time (US & Canada)  \n",
       "3  24-02-2015 11:14               NaN  Pacific Time (US & Canada)  \n",
       "4  24-02-2015 11:13  San Francisco CA  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b51c67b-08af-427f-a860-84cda7b36157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11541 entries, 0 to 11540\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      11541 non-null  float64\n",
      " 1   airline_sentiment             11541 non-null  object \n",
      " 2   airline_sentiment_confidence  11541 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     9508 non-null   float64\n",
      " 5   airline                       11541 non-null  object \n",
      " 6   airline_sentiment_gold        37 non-null     object \n",
      " 7   name                          11541 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 11541 non-null  int64  \n",
      " 10  text                          11541 non-null  object \n",
      " 11  tweet_coord                   838 non-null    object \n",
      " 12  tweet_created                 11541 non-null  object \n",
      " 13  tweet_location                7770 non-null   object \n",
      " 14  user_timezone                 7692 non-null   object \n",
      "dtypes: float64(3), int64(1), object(11)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e93c13f-f2e0-41b4-9074-34a56178a39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset=data[['text','airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59e99170-e84b-4ac6-8719-c33122e24c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0  @VirginAmerica plus you've added commercials t...          positive\n",
       "1  @VirginAmerica it's really aggressive to blast...          negative\n",
       "2  @VirginAmerica and it's a really big bad thing...          negative\n",
       "3  @VirginAmerica seriously would pay $30 a fligh...          negative\n",
       "4  @VirginAmerica yes, nearly every time I fly VX...          positive"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6988957-9ca8-4d6f-8937-0ce21cf23b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Arun\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1eaba613-63ba-4d9a-a75d-7639f67b300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87f5fc00-52cd-4dda-84d1-feec5bccacca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e580831-d41a-4a9e-bc65-b430430fbf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet = WordNetLemmatizer()\n",
    "def text_preproc(x):\n",
    "  x = x.lower()\n",
    "  x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
    "  x = x.encode('ascii', 'ignore').decode()\n",
    "  x = re.sub(r'https*\\S+', ' ', x)\n",
    "  x = re.sub(r'@\\S+', ' ', x)\n",
    "  x = re.sub(r'#\\S+', ' ', x)\n",
    "  x = re.sub(r'\\'\\w+', '', x)\n",
    "  x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
    "  x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
    "  x = re.sub(r'\\s{2,}', ' ', x)\n",
    "  return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c82c7377-9289-4876-b7bd-981b18808779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0  @VirginAmerica plus you've added commercials t...          positive\n",
       "1  @VirginAmerica it's really aggressive to blast...          negative\n",
       "2  @VirginAmerica and it's a really big bad thing...          negative\n",
       "3  @VirginAmerica seriously would pay $30 a fligh...          negative\n",
       "4  @VirginAmerica yes, nearly every time I fly VX...          positive"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97810f65-60af-4526-af2e-d6f4601d71fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset['clean_text']=data_subset['text'].apply(text_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93db026c-b008-4b3d-9712-8b02add7b3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>plus added commercials experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really aggressive blast obnoxious entertainme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>seriously would pay flight seats playing it r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "      <td>yes nearly every time fly vx ear worm wont go...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment  \\\n",
       "0  @VirginAmerica plus you've added commercials t...          positive   \n",
       "1  @VirginAmerica it's really aggressive to blast...          negative   \n",
       "2  @VirginAmerica and it's a really big bad thing...          negative   \n",
       "3  @VirginAmerica seriously would pay $30 a fligh...          negative   \n",
       "4  @VirginAmerica yes, nearly every time I fly VX...          positive   \n",
       "\n",
       "                                          clean_text  \n",
       "0           plus added commercials experience tacky   \n",
       "1   really aggressive blast obnoxious entertainme...  \n",
       "2                               really big bad thing  \n",
       "3   seriously would pay flight seats playing it r...  \n",
       "4   yes nearly every time fly vx ear worm wont go...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbddbf-c556-484d-a91d-19314465daa2",
   "metadata": {},
   "source": [
    "## Basic ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6c0f55e-d161-473d-bb10-d9a5bc087c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(data_subset['clean_text'],data_subset['airline_sentiment'],test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8f49f93a-d344-49cc-bab2-9431e02ffd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(use_idf=True,max_features=10)\n",
    "X_train_tfid=vectorizer.fit_transform(X_train)\n",
    "X_test_tfid=vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "070b6216-2dd1-4cf1-bb1e-ac4b1bbad252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier=MultinomialNB()\n",
    "classifier.fit(X_train_tfid,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01bc93ee-7db4-4f92-9a69-18705bfd7768",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test_tfid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "24ac4223-15ec-4cbf-977b-a2eab41710e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix: [[1796   41]\n",
      " [ 370  102]]\n",
      "**************************\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.98      0.90      1837\n",
      "    positive       0.71      0.22      0.33       472\n",
      "\n",
      "    accuracy                           0.82      2309\n",
      "   macro avg       0.77      0.60      0.61      2309\n",
      "weighted avg       0.81      0.82      0.78      2309\n",
      "\n",
      "**************************\n",
      "\n",
      "accuracy_score : 0.8220008661758337\n",
      "**************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "cf_matrix=confusion_matrix(y_test,y_pred)\n",
    "print(f'Confusion_matrix: {cf_matrix}')\n",
    "print('**************************')\n",
    "print('')\n",
    "clf_report=classification_report(y_test,y_pred)\n",
    "print(f'{clf_report}')\n",
    "print('**************************')\n",
    "print('')\n",
    "Accuracy=accuracy_score(y_test,y_pred)\n",
    "print(f'accuracy_score : {Accuracy}')\n",
    "print('**************************')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "54ba4653-a387-43dc-abb0-6a3993a4194b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score: 0.709011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score,roc_curve, auc\n",
    "\n",
    "# Assuming 'y_test' contains true labels and 'y_pred_proba' contains predicted probabilities\n",
    "y_pred_proba = classifier.predict_proba(X_test_tfid)[:, 1]  # Probability of positive class\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"AUC score: {auc:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883c863d-bb61-4ac3-85bb-2ee085615d8b",
   "metadata": {},
   "source": [
    "## Hybrid Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b8293b9-13e6-482f-8bc0-846a80355ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flight', 3315),\n",
       " ('i', 1104),\n",
       " ('get', 1102),\n",
       " ('cancelled', 956),\n",
       " ('thanks', 920),\n",
       " ('service', 909),\n",
       " ('customer', 724),\n",
       " ('time', 695),\n",
       " ('help', 686),\n",
       " ('hours', 656),\n",
       " ('hold', 621),\n",
       " ('plane', 584),\n",
       " ('amp', 582),\n",
       " ('us', 567),\n",
       " ('thank', 535),\n",
       " ('still', 529),\n",
       " ('delayed', 517),\n",
       " ('can', 502),\n",
       " ('one', 492),\n",
       " ('flights', 478),\n",
       " ('call', 477),\n",
       " ('gate', 476),\n",
       " ('hour', 467),\n",
       " ('flightled', 460),\n",
       " ('you', 456),\n",
       " ('bag', 448),\n",
       " ('back', 448),\n",
       " ('would', 438),\n",
       " ('got', 399),\n",
       " ('late', 395),\n",
       " ('phone', 392),\n",
       " ('need', 391),\n",
       " ('please', 386),\n",
       " ('airline', 374),\n",
       " ('like', 353),\n",
       " ('today', 351),\n",
       " ('waiting', 351),\n",
       " ('guys', 334),\n",
       " ('great', 317),\n",
       " ('that', 316),\n",
       " ('wait', 307),\n",
       " ('u', 306),\n",
       " ('never', 304),\n",
       " ('fly', 303),\n",
       " ('me', 303),\n",
       " ('day', 303),\n",
       " ('trying', 302),\n",
       " ('it', 291),\n",
       " ('delay', 288),\n",
       " ('really', 283),\n",
       " ('airport', 283),\n",
       " ('minutes', 278),\n",
       " ('even', 274),\n",
       " ('going', 271),\n",
       " ('people', 268),\n",
       " ('last', 262),\n",
       " ('way', 262),\n",
       " ('bags', 259),\n",
       " ('weather', 257),\n",
       " ('good', 254),\n",
       " ('know', 254),\n",
       " ('agent', 254),\n",
       " ('home', 252),\n",
       " ('make', 252),\n",
       " ('told', 251),\n",
       " ('luggage', 250),\n",
       " ('another', 244),\n",
       " ('go', 240),\n",
       " ('now', 236),\n",
       " ('ever', 235),\n",
       " ('lost', 235),\n",
       " ('worst', 234),\n",
       " ('flying', 233),\n",
       " ('seat', 232),\n",
       " ('w', 229),\n",
       " ('change', 227),\n",
       " ('check', 226),\n",
       " ('take', 222),\n",
       " ('want', 220),\n",
       " ('hrs', 219),\n",
       " ('due', 218),\n",
       " ('crew', 218),\n",
       " ('getting', 214),\n",
       " ('first', 212),\n",
       " ('days', 212),\n",
       " ('flighted', 211),\n",
       " ('united', 209),\n",
       " ('someone', 208),\n",
       " ('baggage', 207),\n",
       " ('again', 205),\n",
       " ('work', 205),\n",
       " ('much', 204),\n",
       " ('we', 202),\n",
       " ('tomorrow', 202),\n",
       " ('made', 198),\n",
       " ('experience', 197),\n",
       " ('response', 196),\n",
       " ('let', 196),\n",
       " ('could', 193),\n",
       " ('new', 193)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Adding regular expression to data\n",
    "import re\n",
    "from collections import Counter\n",
    "Counter(\" \".join(data_subset['clean_text']).split()).most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "39186cad-9c09-4839-93fd-9caf45577908",
   "metadata": {},
   "outputs": [],
   "source": [
    "Postive_pattern_1 = r\"thanks\"\n",
    "Postive_pattern_2 = r\"thank\"\n",
    "Postive_pattern_3 = r\"great\"\n",
    "Postive_pattern_4 = r\"good\"\n",
    "Postive_pattern_5 = r\"safe\"\n",
    "Postive_pattern_6 = r\"awesome\"\n",
    "Postive_pattern_7 = r\"new\"\n",
    "Postive_pattern_8 = r\"satisfied\"\n",
    "Positive_Pattern_List = [Postive_pattern_1,Postive_pattern_2,Postive_pattern_3,Postive_pattern_4,\n",
    "                        Postive_pattern_5,Postive_pattern_6,Postive_pattern_7,Postive_pattern_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1fae9ccb-565c-44ca-8e52-8b4bdc5d5997",
   "metadata": {},
   "outputs": [],
   "source": [
    "Positive_Complex_Pattern = re.compile('|'.join(['(%s)' % i for i in Positive_Pattern_List]),re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "753352b7-7fbb-4791-b6c1-e5c0cc52d032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'(thanks)|(thank)|(great)|(good)|(safe)|(awesome)|(new)|(satisfied)',\n",
       "           re.IGNORECASE|re.UNICODE)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Positive_Complex_Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f5a1fe8c-d00b-49ad-af9f-a071fe60857b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Negative_pattern_1 = r\"cancelled\"\n",
    "Negative_pattern_2 = r\"delayed\"\n",
    "Negative_pattern_3 = r\"trying\"\n",
    "Negative_pattern_4 = r\"please\"\n",
    "Negative_pattern_5 = r\"wait\"\n",
    "Negative_pattern_6 = r\"worst\"\n",
    "Negative_pattern_7 = r\"lost\"\n",
    "Negative_pattern_8 = r\"never\"\n",
    "Negative_pattern_9 = r\"fraud trans\"\n",
    "\n",
    "Negative_Pattern_List = [Negative_pattern_1,Negative_pattern_2,Negative_pattern_3,Negative_pattern_4,\n",
    "                        Negative_pattern_5,Negative_pattern_6,Negative_pattern_7,Negative_pattern_8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8ff74313-a6d0-4cbf-8f53-1db27982a466",
   "metadata": {},
   "outputs": [],
   "source": [
    "Negative_Complex_Pattern = re.compile('|'.join(['(%s)' % i for i in Negative_Pattern_List]),re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6be3aa13-b2eb-4408-9d1f-3070f07c20dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'(cancelled)|(delayed)|(trying)|(please)|(wait)|(worst)|(lost)|(never)',\n",
       "           re.IGNORECASE|re.UNICODE)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Negative_Complex_Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa45934a-fe47-41c7-bfaf-518b7f5d7306",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset[\"Negative_Sentiment_Flag\"] = data_subset[\"clean_text\"].apply(lambda x:1 if(len(re.findall(Negative_Complex_Pattern,x))>0) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e5dfc28f-d5bc-451d-996a-c1a4a30e16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_subset[\"Positive_Sentiment_Flag\"] = data_subset[\"clean_text\"].apply(lambda x:1 if(len(re.findall(Positive_Complex_Pattern,x))>0) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb486d13-0750-4968-a592-866cf8ff2403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>Negative_Sentiment_Flag</th>\n",
       "      <th>Positive_Sentiment_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "      <td>plus added commercials experience tacky</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really aggressive blast obnoxious entertainme...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "      <td>really big bad thing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>negative</td>\n",
       "      <td>seriously would pay flight seats playing it r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>positive</td>\n",
       "      <td>yes nearly every time fly vx ear worm wont go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11536</th>\n",
       "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
       "      <td>negative</td>\n",
       "      <td>flight cancelled flightled leaving tomorrow m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11537</th>\n",
       "      <td>@AmericanAir right on cue with the delays👌</td>\n",
       "      <td>negative</td>\n",
       "      <td>right cue delays</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11538</th>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thank got different flight chicago</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11539</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>negative</td>\n",
       "      <td>leaving minutes late flight warnings communic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11540</th>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>money change flight answer phones suggestions...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11541 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment  \\\n",
       "0      @VirginAmerica plus you've added commercials t...          positive   \n",
       "1      @VirginAmerica it's really aggressive to blast...          negative   \n",
       "2      @VirginAmerica and it's a really big bad thing...          negative   \n",
       "3      @VirginAmerica seriously would pay $30 a fligh...          negative   \n",
       "4      @VirginAmerica yes, nearly every time I fly VX...          positive   \n",
       "...                                                  ...               ...   \n",
       "11536  @AmericanAir my flight was Cancelled Flightled...          negative   \n",
       "11537         @AmericanAir right on cue with the delays👌          negative   \n",
       "11538  @AmericanAir thank you we got on a different f...          positive   \n",
       "11539  @AmericanAir leaving over 20 minutes Late Flig...          negative   \n",
       "11540  @AmericanAir you have my money, you change my ...          negative   \n",
       "\n",
       "                                              clean_text  \\\n",
       "0               plus added commercials experience tacky    \n",
       "1       really aggressive blast obnoxious entertainme...   \n",
       "2                                   really big bad thing   \n",
       "3       seriously would pay flight seats playing it r...   \n",
       "4       yes nearly every time fly vx ear worm wont go...   \n",
       "...                                                  ...   \n",
       "11536   flight cancelled flightled leaving tomorrow m...   \n",
       "11537                                   right cue delays   \n",
       "11538                thank got different flight chicago    \n",
       "11539   leaving minutes late flight warnings communic...   \n",
       "11540   money change flight answer phones suggestions...   \n",
       "\n",
       "       Negative_Sentiment_Flag  Positive_Sentiment_Flag  \n",
       "0                            0                        0  \n",
       "1                            0                        0  \n",
       "2                            0                        0  \n",
       "3                            0                        0  \n",
       "4                            0                        0  \n",
       "...                        ...                      ...  \n",
       "11536                        1                        0  \n",
       "11537                        0                        0  \n",
       "11538                        0                        1  \n",
       "11539                        0                        0  \n",
       "11540                        0                        0  \n",
       "\n",
       "[11541 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2d590dc1-8e15-458b-a14d-d8fed4aa7d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(re.findall(Positive_Complex_Pattern,' plus added commercials experience tacky '))>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ad8aaae6-c990-4598-a747-2b493098e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_subset[[\"clean_text\",\"Negative_Sentiment_Flag\",\"Positive_Sentiment_Flag\"]],data_subset[\"airline_sentiment\"],test_size=0.1,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0beaace3-9231-47be-ba16-77830bd99d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer(use_idf=True,max_features=10)\n",
    "X_train_tfid=vectorizer.fit_transform(X_train[\"clean_text\"])\n",
    "X_test_tfid=vectorizer.fit_transform(X_test[\"clean_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "aff5b0f0-c2e6-4dce-be46-b10955bf6d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf = pd.DataFrame(X_train_tfid.toarray())\n",
    "mydf_test = pd.DataFrame(X_test_tfid.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b26a1fa5-8890-457c-b7ee-c68c425de0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_columns_train = X_train[[\"Negative_Sentiment_Flag\",\"Positive_Sentiment_Flag\"]]\n",
    "flag_columns_test = X_test[[\"Negative_Sentiment_Flag\",\"Positive_Sentiment_Flag\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "06ed53f5-e691-475b-82dc-1cf1c20615d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vectors_tfidf_combined_with_flag = pd.concat([mydf.reset_index(drop=True),flag_columns_train.reset_index(drop=True)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7572a745-6577-4b2f-8daf-e8a8153d7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_vectors_tfidf_combined_with_flag = pd.concat([mydf_test.reset_index(drop=True),flag_columns_test.reset_index(drop=True)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "77f5efc7-8e56-46c7-b35e-19b0e385dcef",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[120], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m classifier\u001b[38;5;241m=\u001b[39mMultinomialNB()\n\u001b[1;32m----> 2\u001b[0m classifier\u001b[38;5;241m.\u001b[39mfit(X_train_vectors_tfidf_combined_with_flag,y_train)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:745\u001b[0m, in \u001b[0;36m_BaseDiscreteNB.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    726\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit Naive Bayes classifier according to X, y.\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \n\u001b[0;32m    728\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    743\u001b[0m \u001b[38;5;124;03m        Returns the instance itself.\u001b[39;00m\n\u001b[0;32m    744\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 745\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n\u001b[0;32m    746\u001b[0m     _, n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    748\u001b[0m     labelbin \u001b[38;5;241m=\u001b[39m LabelBinarizer()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\naive_bayes.py:578\u001b[0m, in \u001b[0;36m_BaseDiscreteNB._check_X_y\u001b[1;34m(self, X, y, reset)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m    577\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate X and y in fit methods.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(X, y, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, reset\u001b[38;5;241m=\u001b[39mreset)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    516\u001b[0m ):\n\u001b[0;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39mreset)\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:440\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Set or check the `feature_names_in_` attribute.\u001b[39;00m\n\u001b[0;32m    421\u001b[0m \n\u001b[0;32m    422\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;124;03m       should set `reset=False`.\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reset:\n\u001b[1;32m--> 440\u001b[0m     feature_names_in \u001b[38;5;241m=\u001b[39m _get_feature_names(X)\n\u001b[0;32m    441\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m feature_names_in \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    442\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_in_ \u001b[38;5;241m=\u001b[39m feature_names_in\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:2021\u001b[0m, in \u001b[0;36m_get_feature_names\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m   2019\u001b[0m \u001b[38;5;66;03m# mixed type of string and non-string is not supported\u001b[39;00m\n\u001b[0;32m   2020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m types:\n\u001b[1;32m-> 2021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2022\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names are only supported if all input features have string names, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2023\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut your input has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as feature name / column name types. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you want feature names to be stored and validated, you must convert \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthem all to strings, by using X.columns = X.columns.astype(str) for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2026\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample. Otherwise you can remove feature / column names from your input \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2027\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata, or convert them all to a non-string data type.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2028\u001b[0m     )\n\u001b[0;32m   2030\u001b[0m \u001b[38;5;66;03m# Only feature names of all strings are supported\u001b[39;00m\n\u001b[0;32m   2031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(types) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m types[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mTypeError\u001b[0m: Feature names are only supported if all input features have string names, but your input has ['int', 'str'] as feature name / column name types. If you want feature names to be stored and validated, you must convert them all to strings, by using X.columns = X.columns.astype(str) for example. Otherwise you can remove feature / column names from your input data, or convert them all to a non-string data type."
     ]
    }
   ],
   "source": [
    "classifier=MultinomialNB()\n",
    "classifier.fit(X_train_vectors_tfidf_combined_with_flag,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9400ccc-38b9-448d-a97d-40c6d0c2c320",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "cf_matrix=confusion_matrix(y_test,y_pred)\n",
    "print(f'Confusion_matrix: {cf_matrix}')\n",
    "print('**************************')\n",
    "print('')\n",
    "clf_report=classification_report(y_test,y_pred)\n",
    "print(f'{clf_report}')\n",
    "print('**************************')\n",
    "print('')\n",
    "Accuracy=accuracy_score(y_test,y_pred)\n",
    "print(f'accuracy_score : {Accuracy}')\n",
    "print('**************************')\n",
    "print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94740757-5e42-461d-9098-68cad9d2aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score,roc_curve, auc\n",
    "\n",
    "# Assuming 'y_test' contains true labels and 'y_pred_proba' contains predicted probabilities\n",
    "y_pred_proba = classifier.predict_proba(X_test_tfid)[:, 1]  # Probability of positive class\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"AUC score: {auc:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
